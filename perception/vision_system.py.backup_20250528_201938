"""
STARK INDUSTRIES - Vision System
Sistema de visi√≥n por computadora real para el m√≥dulo de percepci√≥n
Implementaci√≥n completa con OpenCV y detecci√≥n de objetos
"""

import cv2
import numpy as np
import threading
import time
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime
import logging
import json
import os
from dataclasses import dataclass
from abc import ABC, abstractmethod

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DetectedObject:
    """Representa un objeto detectado"""
    object_id: str
    class_name: str
    confidence: float
    bounding_box: Tuple[int, int, int, int]  # (x, y, width, height)
    center: Tuple[int, int]
    timestamp: datetime
    properties: Dict[str, Any]

@dataclass
class VisionFrame:
    """Representa un frame procesado"""
    frame_id: str
    timestamp: datetime
    resolution: Tuple[int, int]
    detected_objects: List[DetectedObject]
    frame_data: np.ndarray
    processing_time: float

class VisionProcessor(ABC):
    """Procesador abstracto de visi√≥n"""
    
    @abstractmethod
    def process_frame(self, frame: np.ndarray) -> List[DetectedObject]:
        pass
    
    @abstractmethod
    def get_processor_info(self) -> Dict[str, Any]:
        pass

class OpenCVProcessor(VisionProcessor):
    """Procesador basado en OpenCV"""
    
    def __init__(self):
        self.name = "OpenCV_Processor"
        self.cascade_classifiers = {}
        self._load_classifiers()
        
        # Configuraci√≥n de detecci√≥n
        self.detection_config = {
            "scale_factor": 1.1,
            "min_neighbors": 5,
            "min_size": (30, 30),
            "confidence_threshold": 0.5
        }
        
        logger.info("üîç OpenCV Processor inicializado")
    
    def _load_classifiers(self):
        """Carga clasificadores Haar cascade"""
        try:
            # Intentar cargar clasificadores comunes
            cascades = {
                "face": "haarcascade_frontalface_default.xml",
                "eye": "haarcascade_eye.xml",
                "smile": "haarcascade_smile.xml"
            }
            
            for name, filename in cascades.items():
                try:
                    classifier_path = cv2.data.haarcascades + filename
                    classifier = cv2.CascadeClassifier(classifier_path)
                    if not classifier.empty():
                        self.cascade_classifiers[name] = classifier
                        logger.info(f"Clasificador {name} cargado")
                except Exception as e:
                    logger.warning(f"No se pudo cargar {name}: {e}")
                    
        except Exception as e:
            logger.error(f"Error cargando clasificadores: {e}")
    
    def process_frame(self, frame: np.ndarray) -> List[DetectedObject]:
        """Procesa un frame con OpenCV"""
        detected_objects = []
        
        if frame is None or frame.size == 0:
            return detected_objects
        
        # Convertir a escala de grises para procesamiento
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Detectar con cada clasificador
        for class_name, classifier in self.cascade_classifiers.items():
            try:
                detections = classifier.detectMultiScale(
                    gray,
                    scaleFactor=self.detection_config["scale_factor"],
                    minNeighbors=self.detection_config["min_neighbors"],
                    minSize=self.detection_config["min_size"]
                )
                
                for i, (x, y, w, h) in enumerate(detections):
                    obj_id = f"{class_name}_{i}_{int(time.time())}"
                    center = (x + w // 2, y + h // 2)
                    
                    detected_obj = DetectedObject(
                        object_id=obj_id,
                        class_name=class_name,
                        confidence=0.8,  # Confidence estimada para Haar cascades
                        bounding_box=(x, y, w, h),
                        center=center,
                        timestamp=datetime.now(),
                        properties={"detector": "opencv_haar"}
                    )
                    
                    detected_objects.append(detected_obj)
                    
            except Exception as e:
                logger.error(f"Error detectando {class_name}: {e}")
        
        return detected_objects
    
    def get_processor_info(self) -> Dict[str, Any]:
        """Informaci√≥n del procesador"""
        return {
            "name": self.name,
            "classifiers_loaded": list(self.cascade_classifiers.keys()),
            "detection_config": self.detection_config,
            "opencv_version": cv2.__version__
        }

class MotionDetector(VisionProcessor):
    """Detector de movimiento"""
    
    def __init__(self):
        self.name = "Motion_Detector"
        self.background_subtractor = cv2.createBackgroundSubtractorMOG2(
            detectShadows=True
        )
        self.motion_threshold = 500
        self.min_contour_area = 100
        
        logger.info("üèÉ Motion Detector inicializado")
    
    def process_frame(self, frame: np.ndarray) -> List[DetectedObject]:
        """Detecta movimiento en el frame"""
        detected_objects = []
        
        if frame is None or frame.size == 0:
            return detected_objects
        
        try:
            # Aplicar sustractor de fondo
            fg_mask = self.background_subtractor.apply(frame)
            
            # Encontrar contornos
            contours, _ = cv2.findContours(
                fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                if area > self.min_contour_area:
                    # Obtener bounding rectangle
                    x, y, w, h = cv2.boundingRect(contour)
                    center = (x + w // 2, y + h // 2)
                    
                    # Calcular confidence basada en el √°rea
                    confidence = min(1.0, area / self.motion_threshold)
                    
                    obj_id = f"motion_{i}_{int(time.time())}"
                    
                    detected_obj = DetectedObject(
                        object_id=obj_id,
                        class_name="motion",
                        confidence=confidence,
                        bounding_box=(x, y, w, h),
                        center=center,
                        timestamp=datetime.now(),
                        properties={"area": area, "detector": "motion"}
                    )
                    
                    detected_objects.append(detected_obj)
                    
        except Exception as e:
            logger.error(f"Error en detecci√≥n de movimiento: {e}")
        
        return detected_objects
    
    def get_processor_info(self) -> Dict[str, Any]:
        """Informaci√≥n del detector de movimiento"""
        return {
            "name": self.name,
            "motion_threshold": self.motion_threshold,
            "min_contour_area": self.min_contour_area,
            "background_model": "MOG2"
        }

class ColorDetector(VisionProcessor):
    """Detector de colores espec√≠ficos"""
    
    def __init__(self):
        self.name = "Color_Detector"
        self.color_ranges = {
            "red": [(0, 50, 50), (10, 255, 255)],
            "blue": [(100, 50, 50), (130, 255, 255)],
            "green": [(40, 50, 50), (80, 255, 255)],
            "yellow": [(20, 50, 50), (30, 255, 255)]
        }
        
        logger.info("üé® Color Detector inicializado")
    
    def process_frame(self, frame: np.ndarray) -> List[DetectedObject]:
        """Detecta colores espec√≠ficos en el frame"""
        detected_objects = []
        
        if frame is None or frame.size == 0:
            return detected_objects
        
        try:
            # Convertir a HSV para mejor detecci√≥n de color
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            for color_name, (lower, upper) in self.color_ranges.items():
                # Crear m√°scara para el color
                lower_bound = np.array(lower)
                upper_bound = np.array(upper)
                mask = cv2.inRange(hsv, lower_bound, upper_bound)
                
                # Encontrar contornos
                contours, _ = cv2.findContours(
                    mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                )
                
                for i, contour in enumerate(contours):
                    area = cv2.contourArea(contour)
                    
                    if area > 300:  # Filtrar √°reas peque√±as
                        x, y, w, h = cv2.boundingRect(contour)
                        center = (x + w // 2, y + h // 2)
                        
                        # Confidence basada en el √°rea
                        confidence = min(1.0, area / 5000)
                        
                        obj_id = f"{color_name}_{i}_{int(time.time())}"
                        
                        detected_obj = DetectedObject(
                            object_id=obj_id,
                            class_name=f"color_{color_name}",
                            confidence=confidence,
                            bounding_box=(x, y, w, h),
                            center=center,
                            timestamp=datetime.now(),
                            properties={
                                "color": color_name,
                                "area": area,
                                "detector": "color"
                            }
                        )
                        
                        detected_objects.append(detected_obj)
                        
        except Exception as e:
            logger.error(f"Error en detecci√≥n de colores: {e}")
        
        return detected_objects
    
    def get_processor_info(self) -> Dict[str, Any]:
        """Informaci√≥n del detector de colores"""
        return {
            "name": self.name,
            "supported_colors": list(self.color_ranges.keys()),
            "color_space": "HSV"
        }

class StarkVisionSystem:
    """
    Sistema de visi√≥n principal de STARK Industries
    Coordina m√∫ltiples procesadores de visi√≥n
    """
    
    def __init__(self, camera_index: int = 0):
        self.camera_index = camera_index
        self.camera = None
        self.active = False
        self.processing_thread = None
        self.frame_rate = 30
        
        # Procesadores disponibles
        self.processors = {
            "opencv": OpenCVProcessor(),
            "motion": MotionDetector(),
            "color": ColorDetector()
        }
        
        self.enabled_processors = ["opencv", "motion", "color"]
        
        # Estado y resultados
        self.current_frame = None
        self.last_detection_results = []
        self.processing_stats = {
            "frames_processed": 0,
            "total_objects_detected": 0,
            "average_processing_time": 0.0,
            "last_update": datetime.now()
        }
        
        # Callbacks para eventos
        self.detection_callbacks: List[Callable] = []
        
        logger.info("üëÅÔ∏è STARK Vision System inicializado")
    
    def initialize_camera(self) -> bool:
        """Inicializa la c√°mara"""
        try:
            self.camera = cv2.VideoCapture(self.camera_index)
            
            if not self.camera.isOpened():
                logger.error("No se pudo abrir la c√°mara")
                return False
            
            # Configurar propiedades de la c√°mara
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, self.frame_rate)
            
            logger.info("üìπ C√°mara inicializada correctamente")
            return True
            
        except Exception as e:
            logger.error(f"Error inicializando c√°mara: {e}")
            return False
    
    def start_processing(self) -> bool:
        """Inicia el procesamiento de video"""
        if not self.initialize_camera():
            return False
        
        self.active = True
        self.processing_thread = threading.Thread(target=self._processing_loop)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        logger.info("üöÄ Procesamiento de visi√≥n iniciado")
        return True
    
    def stop_processing(self):
        """Detiene el procesamiento de video"""
        self.active = False
        
        if self.processing_thread:
            self.processing_thread.join(timeout=2.0)
        
        if self.camera:
            self.camera.release()
        
        logger.info("‚èπÔ∏è Procesamiento de visi√≥n detenido")
    
    def _processing_loop(self):
        """Bucle principal de procesamiento"""
        frame_time = 1.0 / self.frame_rate
        
        while self.active:
            try:
                start_time = time.time()
                
                # Capturar frame
                ret, frame = self.camera.read()
                if not ret:
                    continue
                
                self.current_frame = frame.copy()
                
                # Procesar con todos los procesadores habilitados
                all_detections = []
                
                for processor_name in self.enabled_processors:
                    if processor_name in self.processors:
                        processor = self.processors[processor_name]
                        detections = processor.process_frame(frame)
                        all_detections.extend(detections)
                
                # Actualizar resultados
                self.last_detection_results = all_detections
                
                # Ejecutar callbacks
                for callback in self.detection_callbacks:
                    try:
                        callback(all_detections, frame)
                    except Exception as e:
                        logger.error(f"Error en callback: {e}")
                
                # Actualizar estad√≠sticas
                processing_time = time.time() - start_time
                self._update_stats(processing_time, len(all_detections))
                
                # Control de frame rate
                sleep_time = max(0, frame_time - processing_time)
                time.sleep(sleep_time)
                
            except Exception as e:
                logger.error(f"Error en bucle de procesamiento: {e}")
                time.sleep(0.1)
    
    def _update_stats(self, processing_time: float, objects_detected: int):
        """Actualiza estad√≠sticas de procesamiento"""
        self.processing_stats["frames_processed"] += 1
        self.processing_stats["total_objects_detected"] += objects_detected
        
        # Promedio m√≥vil del tiempo de procesamiento
        if self.processing_stats["average_processing_time"] == 0.0:
            self.processing_stats["average_processing_time"] = processing_time
        else:
            alpha = 0.1  # Factor de suavizado
            self.processing_stats["average_processing_time"] = (
                alpha * processing_time + 
                (1 - alpha) * self.processing_stats["average_processing_time"]
            )
        
        self.processing_stats["last_update"] = datetime.now()
    
    def get_current_frame(self) -> Optional[np.ndarray]:
        """Obtiene el frame actual"""
        return self.current_frame.copy() if self.current_frame is not None else None
    
    def get_detections(self) -> List[DetectedObject]:
        """Obtiene las √∫ltimas detecciones"""
        return self.last_detection_results.copy()
    
    def add_detection_callback(self, callback: Callable):
        """Agrega un callback para detecciones"""
        self.detection_callbacks.append(callback)
    
    def enable_processor(self, processor_name: str):
        """Habilita un procesador espec√≠fico"""
        if processor_name in self.processors:
            if processor_name not in self.enabled_processors:
                self.enabled_processors.append(processor_name)
                logger.info(f"Procesador {processor_name} habilitado")
    
    def disable_processor(self, processor_name: str):
        """Deshabilita un procesador espec√≠fico"""
        if processor_name in self.enabled_processors:
            self.enabled_processors.remove(processor_name)
            logger.info(f"Procesador {processor_name} deshabilitado")
    
    def get_system_info(self) -> Dict[str, Any]:
        """Obtiene informaci√≥n del sistema"""
        return {
            "active": self.active,
            "camera_index": self.camera_index,
            "frame_rate": self.frame_rate,
            "enabled_processors": self.enabled_processors,
            "available_processors": list(self.processors.keys()),
            "processing_stats": self.processing_stats.copy(),
            "opencv_version": cv2.__version__
        }
    
    def capture_image(self, filename: str = None) -> bool:
        """Captura una imagen del frame actual"""
        try:
            if self.current_frame is None:
                return False
            
            if filename is None:
                filename = f"stark_capture_{int(time.time())}.jpg"
            
            cv2.imwrite(filename, self.current_frame)
            logger.info(f"Imagen capturada: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"Error capturando imagen: {e}")
            return False
    
    def process_image_file(self, image_path: str) -> List[DetectedObject]:
        """Procesa una imagen desde archivo"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                logger.error(f"No se pudo cargar la imagen: {image_path}")
                return []
            
            all_detections = []
            
            for processor_name in self.enabled_processors:
                if processor_name in self.processors:
                    processor = self.processors[processor_name]
                    detections = processor.process_frame(image)
                    all_detections.extend(detections)
            
            logger.info(f"Procesada imagen {image_path}: {len(all_detections)} objetos detectados")
            return all_detections
            
        except Exception as e:
            logger.error(f"Error procesando imagen: {e}")
            return []

# Funci√≥n principal para crear el sistema de visi√≥n
def create_vision_system(camera_index: int = 0) -> StarkVisionSystem:
    """Crea y configura el sistema de visi√≥n STARK"""
    return StarkVisionSystem(camera_index)

# Funci√≥n de prueba
def test_vision_system():
    """Prueba b√°sica del sistema de visi√≥n"""
    vision = create_vision_system()
    
    def detection_handler(detections, frame):
        print(f"Detectados {len(detections)} objetos")
        for detection in detections:
            print(f"  - {detection.class_name} (confianza: {detection.confidence:.2f})")
    
    vision.add_detection_callback(detection_handler)
    
    print("Iniciando sistema de visi√≥n...")
    if vision.start_processing():
        print("Sistema activo. Presiona Ctrl+C para detener.")
        try:
            time.sleep(10)  # Ejecutar por 10 segundos
        except KeyboardInterrupt:
            pass
        finally:
            vision.stop_processing()
    else:
        print("Error iniciando sistema de visi√≥n")

if __name__ == "__main__":
    test_vision_system()
